{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alike-notice",
   "metadata": {},
   "source": [
    "# Wpływ cech czerwonego wina na jego jakość - prezentacja wytrenowanych modeli\n",
    "## Autorzy: Jakub Kosterna, Bartosz Siński, Jan Smoleń"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinate-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-stamp",
   "metadata": {},
   "source": [
    "### Załadowanie zbioru danych i podział na zbiory treningowe i testowe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agricultural-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "df_wines = pd.read_csv('./src/winequality-red.csv')\n",
    "df_wines[\"is_good\"] = df_wines.apply(lambda row: 1 if row.quality > 5 else 0, axis = 1)\n",
    "X=df_wines.drop([\"is_good\", 'quality'], axis=1)\n",
    "y=df_wines[\"is_good\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-camel",
   "metadata": {},
   "source": [
    "### Base SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "provincial-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_base=SVC(random_state=42)\n",
    "svm_base.fit(X_train, y_train)\n",
    "preds=svm_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imposed-taiwan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6375"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(preds,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-integral",
   "metadata": {},
   "source": [
    "Wynik surowego SVM na naszym zbiorze danych to około 75%. Tera poszukamy kombinacji parametrów dających najlepsze wyniki używając narzędzia `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-shannon",
   "metadata": {},
   "source": [
    "### Tuning hiperparametrów dla SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "scheduled-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "cpar=[]\n",
    "gpar=[]\n",
    "for i in range(-4, 5):\n",
    "    cpar.append(10**i)\n",
    "for i in range(-4, 5):\n",
    "    gpar.append(10**i)\n",
    "gpar.append(\"auto\")\n",
    "gpar.append(\"scale\")\n",
    "params = [{'C': cpar,\n",
    "        'kernel': [\"rbf\"], # \"linear\", \"poly\"],    bardzo długi czas wykonywania\n",
    "        'gamma': gpar}]\n",
    "svm_tuned=SVC(random_state=42)\n",
    "gs_svm=GridSearchCV(svm_tuned, param_grid=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "gs_svm.fit(X_train, y_train)\n",
    "gs_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worth-plane",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7475"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gs_svm.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-reservoir",
   "metadata": {},
   "source": [
    "Po dosyć długim przetestowaniu różnych kombinacji hiperparametrów używając narzędzia GridSearchCV, najlepszy wynik uzyskaliśmy dla {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}. Sprawdziliśmy następnie jeszcze wartości w okolicach tych parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "choice-rabbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2000, 'gamma': 0.0006, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpar=[]\n",
    "gpar=[]\n",
    "for i in range(1, 11):\n",
    "    cpar.append(round((10**3)*2*i, 8))\n",
    "for i in range(1, 11):\n",
    "    gpar.append(round((10**-4)*2*i, 8))\n",
    "params = [{'C': cpar,\n",
    "         'kernel': [\"rbf\"],\n",
    "         'gamma': gpar}]\n",
    "svm_tuned=SVC(random_state=42)\n",
    "gs_svm=GridSearchCV(svm_tuned, param_grid=params, scoring='accuracy', cv=4, n_jobs=2)\n",
    "gs_svm.fit(X_train, y_train)\n",
    "gs_svm.best_params_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "physical-shannon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcr = gs_svm.predict(X_test)\n",
    "accuracy_score(gs_svm.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-compression",
   "metadata": {},
   "source": [
    "Udało się jeszcze trochę polepszyć wyniki naszego modelu przyjmując parametry `{'C': 2000, 'gamma': 0.0006, 'kernel': 'rbf'}`, osiągając skuteczność powyżej 75%. Nie są to jednak duże różnice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-british",
   "metadata": {},
   "source": [
    "Używając SVM nie udało się siągnąć wyniku tak dobrego jak w przypadku np. xgboosta. Powodem tego jest zapewne spore nakładanie się na siebie naszych dwóch klas - w końcu granica pomiędzy nimi to różnica między subiektywną oceną 5 a 6 w 10 stopniowej skali, a SVM nie radzi sobie szczególnie dobrze z takimi problemami. Jest on też dosyć wolny - testowanie różnych konfiguracji parametrów, szczególnie przy użyciu opcji `kernel=poly`, zajmowało godziny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-christian",
   "metadata": {},
   "source": [
    "### Random Forest z domyślnymi parametrami "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beginning-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=1613)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1613)\n",
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stunning-closing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7875"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(rfc.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-frederick",
   "metadata": {},
   "source": [
    "Klasyfikator Random Forest z ustawionymi domyslnymi parametrami poradził sobie lepiej na naszym zbiorze danych niż SVM i jednocześnie gorzej niż XBoost. Zobaczmy jak sytuacja będzie wyglądać po tuningu hiperparametrów naszego Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-courage",
   "metadata": {},
   "source": [
    "### Random Forest z tuningiem hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "freelance-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7925"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rfc2 = RandomForestClassifier(random_state=1613)\n",
    "grid = {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "rfct = RandomizedSearchCV(estimator = rfc2,param_distributions = grid, cv=4,n_iter=10, random_state=42)\n",
    "rfct.fit(X_train,y_train)\n",
    "accuracy_score(rfct.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "handed-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1000,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 80,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfct.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-perspective",
   "metadata": {},
   "source": [
    "Udało nam się poprawić accuracy o 0,5% . Teraz poszukamy parametrów w otoczeniu tych, które poprawiają predykcje naszego modelu. Użyjemy do tego GridSearchCV, który zamiast wybierać próbki z rozkładów parametrów, bierze wszystkie kombinacje podanych mu parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "secondary-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 180 candidates, totalling 720 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.795"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc2 = RandomForestClassifier(random_state=1613)\n",
    "grid2 = {'bootstrap': [True],\n",
    " 'max_depth': [ 75, 80, 85,90],\n",
    " 'max_features': ['auto'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 3, 4],\n",
    " 'n_estimators': [ 900,950, 1000,1050,1100]}\n",
    "rfcg = GridSearchCV(estimator = rfc2, param_grid = grid2, cv = 4, n_jobs = -1, verbose = 2)\n",
    "rfcg.fit(X_train,y_train)\n",
    "accuracy_score(rfcg.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "piano-colleague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 75,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1050}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = rfcg.predict(X_test)\n",
    "rfcg.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-fusion",
   "metadata": {},
   "source": [
    "Jak widzimy udało się jeszcze podnieść accuracy jeszcze  o 0,25%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-rugby",
   "metadata": {},
   "source": [
    "### XGBoost bez poszukiwań dobrych parametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "geological-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:39:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier(objective = \"binary:logistic\", seed = 1613, use_label_encoder=False)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "predsxg = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expanded-ethics",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predsxg,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-central",
   "metadata": {},
   "source": [
    "Nawet bez boosting XGBoost wykazuje się najlepszym accuracy sposród wszystkich badanych przez nas modeli, chociaż jest on bardzo blisko Random Forest z dobranymi hiperparametrami. Spójrzmy jaki będzie rezultat z tuningiem hiperparametrów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-storage",
   "metadata": {},
   "source": [
    "### XGBoost z tuningiem hiperparametrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "valid-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 1,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.05,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "gbm_param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30] ,\n",
    "    \"max_depth\": [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "    \"min_child_weight\": [ 1, 3, 5, 7],\n",
    "    \"gamma\": [ 0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "    \"colsample_bytree\": [ 0.3, 0.4, 0.5 , 0.7]\n",
    "}\n",
    "\n",
    "gbm = xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = \"logloss\", use_label_encoder = False, seed = 42)\n",
    "\n",
    "randomized_mse = RandomizedSearchCV(param_distributions = gbm_param_grid,\n",
    "    estimator = gbm,\n",
    "    cv = 4,\n",
    "    n_iter = 1000)\n",
    "\n",
    "randomized_mse.fit(X_train, y_train)\n",
    "randomized_mse.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recent-leeds",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsxg2 = randomized_mse.predict(X_test)\n",
    "accuracy_score(predsxg2,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-passing",
   "metadata": {},
   "source": [
    "Dobór parametrów poprawił accuracy naszego XGBoosta o 1% co jest zdecydowanie najlepszym uzyskanym przez nas wynikiem. Powyżej badalismy jedynie metrykę accuracy, zobaczmy jak predykcje modeli różnią się także przy zastosowaniu innych metryk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-nickel",
   "metadata": {},
   "source": [
    "### Ocena modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "knowing-victor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.791878</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>0.754271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.793639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.808713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       algorithm  accuracy  precision    recall   ROC AUC\n",
       "0            SVC    0.7525   0.791878  0.728972  0.754271\n",
       "1  Random Forest    0.7950   0.805556  0.813084  0.793639\n",
       "2        XGBoost    0.8100   0.819444  0.827103  0.808713"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "results = {\n",
    "    \"algorithm\" : ['SVC','Random Forest','XGBoost'],\n",
    "    \"accuracy\" : [accuracy_score(y_test,svcr),accuracy_score(y_test,rf),accuracy_score(y_test,predsxg2)],\n",
    "    \"precision\" : [precision_score(y_test,svcr),precision_score(y_test,rf),precision_score(y_test,predsxg2)],\n",
    "    \"recall\" :[recall_score(y_test,svcr),recall_score(y_test,rf),recall_score(y_test,predsxg2)],\n",
    "    'ROC AUC' : [roc_auc_score(y_test,svcr),roc_auc_score(y_test,rf),roc_auc_score(y_test,predsxg2)]\n",
    "}\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-oklahoma",
   "metadata": {},
   "source": [
    "Jak widzimy model oparty na SVC miał precyzje zbliżoną do Random Forrest i XGBoost jednak bardzo odstający *recall*. Różnice wartość ROC AUC między modelami są takie same jak dla metryki accuracy. Dodatkowo spójrzmy na *table of confusion* dla tych modeli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-accuracy",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "radio-albert",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual positives</th>\n",
       "      <th>Actual negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive predictions</th>\n",
       "      <td>156</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative predictions</th>\n",
       "      <td>41</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Actual positives  Actual negatives\n",
       "Positive predictions               156                58\n",
       "Negative predictions                41               145"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, svcr).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-arrival",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "stretch-sheet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual positives</th>\n",
       "      <th>Actual negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive predictions</th>\n",
       "      <td>174</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative predictions</th>\n",
       "      <td>42</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Actual positives  Actual negatives\n",
       "Positive predictions               174                40\n",
       "Negative predictions                42               144"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, rf).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-capitol",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sitting-panic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual positives</th>\n",
       "      <th>Actual negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Positive predictions</th>\n",
       "      <td>177</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative predictions</th>\n",
       "      <td>39</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Actual positives  Actual negatives\n",
       "Positive predictions               177                37\n",
       "Negative predictions                39               147"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predsxg2).ravel()\n",
    "pd.DataFrame({\"Actual positives\": [tp, fp], \"Actual negatives\": [fn, tn]}, index = [\"Positive predictions\", \"Negative predictions\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
